{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection EDA\n",
    "Comprehensive exploratory data analysis for a large-scale transaction dataset with a binary fraud target.\n",
    "\n",
    "This notebook loads a dataset, summarizes schema and statistics, inspects categorical distributions,\n",
    "assesses class imbalance, quantifies missingness, analyzes transaction amount, and visualizes\n",
    "correlations including a numeric target representation." ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Ensure project root is on path for module imports\n",
    "sys.path.append(os.getcwd())\n",
    "from eda import eda_fraud as eda\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='notebook')\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 160)\n",
    "RANDOM_STATE = 42\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_PATH = None  # e.g., '../data/transactions.csv' (leave None to auto-discover)\n",
    "COLUMN_HINTS = {\n",
    "    'target': None,            # e.g., 'is_fraud' or 'fraudulent'\n",
    "    'amount': None,            # e.g., 'transaction_amount'\n",
    "    'timestamp': None,         # e.g., 'transaction_time'\n",
    "    'merchant_category': None, # e.g., 'merchant_category' or 'mcc'\n",
    "    'device_type': None,       # e.g., 'device_type'\n",
    "    'device_os': None,         # e.g., 'os'\n",
    "    'user_gender': None,       # e.g., 'gender'\n",
    "    'user_age': None,          # e.g., 'age'\n",
    "    'user_income': None        # e.g., 'income'\n",
    "}\n",
    "PLOT_SAMPLE_N = 300000\n",
    "AUTO_FIND_DATA = True\n",
    "print('Configured. Set DATASET_PATH if auto-discovery fails.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df, path = eda.load_dataset(DATASET_PATH, auto_find_data=AUTO_FIND_DATA)\n",
    "print(f'Loaded: {path}')\n",
    "print(f'Rows: {len(df)}  Columns: {df.shape[1]}')\n",
    "display(df.head(3))\n",
    "# Normalize column names (strip spaces)\n",
    "df.columns = [c.strip() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema and statistical summary\n",
    "print('DataFrame info:')\n",
    "df.info()\n",
    "\n",
    "print('\nDescriptive statistics (numeric):')\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer columns and feature groups\n",
    "inferred = eda.infer_columns(df, COLUMN_HINTS)\n",
    "print('Inferred columns:')\n",
    "for k, v in inferred.items():\n",
    "    if v is not None:\n",
    "        print(f'  {k:>18}: {v}')\n",
    "features = eda.build_feature_groups(df, target_col=inferred.get('target'))\n",
    "display(pd.Series({k: len(v) for k, v in features.items()}).to_frame('count'))\n",
    "# Ensure timestamp parsed if present\n",
    "ts_col = inferred.get('timestamp')\n",
    "if ts_col and not pd.api.types.is_datetime64_any_dtype(df[ts_col]):\n",
    "    df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target class imbalance\n",
    "_y, _pos = eda.class_imbalance(df, inferred.get('target'))\n",
    "# _y maps target to {0,1} and stores as df['__y__'] when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: percentage per column and visualization\n",
    "miss = df.isna().mean().sort_values(ascending=False)\n",
    "display(miss.to_frame('missing_rate').style.format({'missing_rate': '{:.2%}'}))\n",
    "top_missing = miss[miss > 0].head(30)\n",
    "if not top_missing.empty:\n",
    "    plt.figure(figsize=(10, max(3, 0.3*len(top_missing))))\n",
    "    sns.barplot(x=top_missing.values, y=top_missing.index, color='#4C78A8')\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x:.0%}'))\n",
    "    plt.title('Top missingness per column')\n",
    "    plt.xlabel('Missing rate'); plt.ylabel('Column')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Missingness heatmap (sampled) via helper\n",
    "eda.missingness(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical distributions: merchant category, device info, user demographics\n",
    "cat_keys = [\n",
    "    'merchant_category', 'device_type', 'device_os', 'user_gender', 'user_age', 'user_income', 'country', 'state', 'city'\n",
    "]\n",
    "cats = [inferred.get(k) for k in cat_keys if inferred.get(k) in df.columns]\n",
    "if not cats:\n",
    "    # Fallback: auto-detected categorical columns with reasonable cardinality\n",
    "    cats = []\n",
    "    for c in features.get('categorical', []):\n",
    "        k = df[c].nunique(dropna=True)\n",
    "        if 2 <= k <= 50:\n",
    "            cats.append(c)\n",
    "    cats = cats[:8]\n",
    "for col in cats:\n",
    "    display(pd.DataFrame(df[col].value_counts(dropna=False).head(20), columns=['count']))\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    vc = df[col].value_counts(dropna=False).head(20)\n",
    "    sns.barplot(x=vc.values, y=vc.index.astype(str), color='#4C78A8')\n",
    "    plt.title(f'{col} top levels')\n",
    "    plt.xlabel('Count'); plt.ylabel(col)\n",
    "    plt.tight_layout(); plt.show()\n",
    "    if '__y__' in df.columns:\n",
    "        gr = df.groupby(col)['__y__'].mean().sort_values(ascending=False).head(20)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.barplot(x=gr.values, y=gr.index.astype(str), color='#F58518')\n",
    "        plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x:.1%}'))\n",
    "        plt.title(f'Fraud rate by {col}')\n",
    "        plt.xlabel('Fraud rate'); plt.ylabel(col)\n",
    "        plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount analysis: summary, histogram, box plot\n",
    "amount_col = inferred.get('amount')\n",
    "if amount_col and amount_col in df.columns and pd.api.types.is_numeric_dtype(df[amount_col]):\n",
    "    print(f'Amount column: {amount_col}')\n",
    "    display(df[amount_col].describe().to_frame('value'))\n",
    "    try:\n",
    "        skew_val = df[amount_col].skew(skipna=True)\n",
    "        print(f'Skewness: {skew_val:.4f}')\n",
    "    except Exception:\n",
    "        pass\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.histplot(df[amount_col].dropna(), kde=True, ax=axes[0], color='#4C78A8')\n",
    "    axes[0].set_title(f'{amount_col} distribution')\n",
    "    sns.boxplot(x=df[amount_col].dropna(), ax=axes[1], color='#F58518')\n",
    "    axes[1].set_title(f'{amount_col} box plot')\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('Transaction amount column not found or not numeric.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix including numeric target\n",
    "num_cols = features.get('numeric', [])\n",
    "cols_for_corr = list(num_cols)\n",
    "if '__y__' in df.columns:\n",
    "    cols_for_corr = cols_for_corr + ['__y__']\n",
    "df_corr = df[cols_for_corr].copy()\n",
    "# Drop near-constant columns to improve readability\n",
    "keep = []\n",
    "for c in cols_for_corr:\n",
    "    try:\n",
    "        if df_corr[c].nunique(dropna=True) > 1:\n",
    "            keep.append(c)\n",
    "    except Exception:\n",
    "        pass\n",
    "df_corr = df_corr[keep]\n",
    "corr = df_corr.corr(method='pearson')\n",
    "plt.figure(figsize=(min(1 + 0.4*len(corr), 14), min(1 + 0.4*len(corr), 14)))\n",
    "sns.heatmap(corr, cmap='vlag', center=0, square=True)\n",
    "plt.title('Correlation heatmap (including target if available)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- **Feature engineering**: time-based aggregations, user/merchant risk features, device/IP reputation, target encoding for high-cardinality categories.\n",
    "- **Preprocessing**: imputation, log-transform skewed amounts, scaling, outlier capping.\n",
    "- **Model design**: time-aware splits, class weighting or resampling, calibration, SHAP/feature importance for interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
